{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlt2kbDaUGuYVhWNxegZbu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anirudh3104/BDA-Assignment-2/blob/main/BDAAssignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Big Data Analytics Assignment**"
      ],
      "metadata": {
        "id": "JC8UxzF2lG4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIUwrcw3CI3T",
        "outputId": "e8f8c37b-1550-4604-f26c-be2cefd2eacc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***ðŸ“§ Spam Classification using Decision Tree in PySpark***"
      ],
      "metadata": {
        "id": "gHCuV10NwuFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install and Load SMS Spam Collection Dataset\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Download and extract the dataset\n",
        "dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\"\n",
        "urllib.request.urlretrieve(dataset_url, \"smsspamcollection.zip\")\n",
        "\n",
        "with zipfile.ZipFile(\"smsspamcollection.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "# Load into pandas DataFrame\n",
        "df = pd.read_csv(\"SMSSpamCollection\", sep='\\t', names=[\"label\", \"message\"])\n",
        "df[\"label\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1})  # Binary Encoding\n",
        "\n",
        "# Step 2: Initialize Spark Session and Convert to Spark DataFrame\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"SMS Spam Detection\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark_df = spark.createDataFrame(df)\n",
        "spark_df.show(5, truncate=False)\n",
        "\n",
        "# Step 3: Preprocess Text and Extract Features\n",
        "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"message\", outputCol=\"words\")\n",
        "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "\n",
        "# Step 4: Initialize and Apply Decision Tree Classifier\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "decision_tree = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
        "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, decision_tree])\n",
        "\n",
        "# Train the Model\n",
        "model = pipeline.fit(spark_df)\n",
        "\n",
        "# Step 5: Generate Predictions and Evaluate Model\n",
        "predictions = model.transform(spark_df)\n",
        "predictions.select(\"message\", \"label\", \"prediction\").show(5, truncate=False)\n",
        "\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkBBhqAovy1j",
        "outputId": "ca28a682-0509-41c7-b360-551e676be899"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|label|message                                                                                                                                                    |\n",
            "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|0    |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |\n",
            "|0    |Ok lar... Joking wif u oni...                                                                                                                              |\n",
            "|1    |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|\n",
            "|0    |U dun say so early hor... U c already then say...                                                                                                          |\n",
            "|0    |Nah I don't think he goes to usf, he lives around here though                                                                                              |\n",
            "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------+-----+----------+\n",
            "|message                                                                                                                                                    |label|prediction|\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------+-----+----------+\n",
            "|Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |0    |0.0       |\n",
            "|Ok lar... Joking wif u oni...                                                                                                                              |0    |0.0       |\n",
            "|Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|1    |1.0       |\n",
            "|U dun say so early hor... U c already then say...                                                                                                          |0    |0.0       |\n",
            "|Nah I don't think he goes to usf, he lives around here though                                                                                              |0    |0.0       |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------+-----+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Model Accuracy: 0.9494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***KMeans Clustering on Wine Dataset using PySpark***"
      ],
      "metadata": {
        "id": "eCo-GF2Y0qxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Required Libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "from sklearn.datasets import load_wine\n",
        "import pandas as pd\n",
        "\n",
        "# Step 2: Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"KMeans Clustering - Wine Dataset\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 3: Load Wine Dataset from scikit-learn\n",
        "wine_data = load_wine()\n",
        "\n",
        "# Convert the wine data into a Pandas DataFrame for easier manipulation and inspection\n",
        "df = pd.DataFrame(wine_data.data, columns=wine_data.feature_names)\n",
        "df['target'] = wine_data.target  # Add the target column (which indicates the wine class)\n",
        "\n",
        "# Step 4: Convert Pandas DataFrame to Spark DataFrame\n",
        "spark_df = spark.createDataFrame(df)\n",
        "\n",
        "# Show the first few rows to understand the data\n",
        "spark_df.show(5)\n",
        "\n",
        "# Step 5: Feature Engineering - Assemble Features\n",
        "assembler = VectorAssembler(inputCols=wine_data.feature_names, outputCol=\"features\")\n",
        "spark_df = assembler.transform(spark_df)\n",
        "\n",
        "# Step 6: Apply KMeans Clustering\n",
        "kmeans = KMeans().setK(3).setSeed(1)  # 3 clusters (Wine dataset has 3 classes), set seed for reproducibility\n",
        "model = kmeans.fit(spark_df)\n",
        "\n",
        "# Step 7: Make Predictions\n",
        "predictions = model.transform(spark_df)\n",
        "\n",
        "# Step 8: Show the Results\n",
        "predictions.select(\"features\", \"target\", \"prediction\").show(5, truncate=False)\n",
        "\n",
        "# Step 9: Evaluate the Clustering Performance\n",
        "evaluator = ClusteringEvaluator()\n",
        "silhouette_score = evaluator.evaluate(predictions)\n",
        "print(f\"Silhouette Score: {silhouette_score:.4f}\")\n",
        "\n",
        "# Step 10: Show Cluster Centers (Centroids)\n",
        "centers = model.clusterCenters()\n",
        "print(\"Cluster Centers (Centroids):\")\n",
        "for center in centers:\n",
        "    print(center)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmzF1AJWxoEa",
        "outputId": "01e29743-9b2e-4973-fb18-2e35e75d3b65"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+----+-----------------+---------+-------------+----------+--------------------+---------------+---------------+----+----------------------------+-------+------+\n",
            "|alcohol|malic_acid| ash|alcalinity_of_ash|magnesium|total_phenols|flavanoids|nonflavanoid_phenols|proanthocyanins|color_intensity| hue|od280/od315_of_diluted_wines|proline|target|\n",
            "+-------+----------+----+-----------------+---------+-------------+----------+--------------------+---------------+---------------+----+----------------------------+-------+------+\n",
            "|  14.23|      1.71|2.43|             15.6|    127.0|          2.8|      3.06|                0.28|           2.29|           5.64|1.04|                        3.92| 1065.0|     0|\n",
            "|   13.2|      1.78|2.14|             11.2|    100.0|         2.65|      2.76|                0.26|           1.28|           4.38|1.05|                         3.4| 1050.0|     0|\n",
            "|  13.16|      2.36|2.67|             18.6|    101.0|          2.8|      3.24|                 0.3|           2.81|           5.68|1.03|                        3.17| 1185.0|     0|\n",
            "|  14.37|      1.95| 2.5|             16.8|    113.0|         3.85|      3.49|                0.24|           2.18|            7.8|0.86|                        3.45| 1480.0|     0|\n",
            "|  13.24|      2.59|2.87|             21.0|    118.0|          2.8|      2.69|                0.39|           1.82|           4.32|1.04|                        2.93|  735.0|     0|\n",
            "+-------+----------+----+-----------------+---------+-------------+----------+--------------------+---------------+---------------+----+----------------------------+-------+------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+---------------------------------------------------------------------+------+----------+\n",
            "|features                                                             |target|prediction|\n",
            "+---------------------------------------------------------------------+------+----------+\n",
            "|[14.23,1.71,2.43,15.6,127.0,2.8,3.06,0.28,2.29,5.64,1.04,3.92,1065.0]|0     |2         |\n",
            "|[13.2,1.78,2.14,11.2,100.0,2.65,2.76,0.26,1.28,4.38,1.05,3.4,1050.0] |0     |2         |\n",
            "|[13.16,2.36,2.67,18.6,101.0,2.8,3.24,0.3,2.81,5.68,1.03,3.17,1185.0] |0     |1         |\n",
            "|[14.37,1.95,2.5,16.8,113.0,3.85,3.49,0.24,2.18,7.8,0.86,3.45,1480.0] |0     |1         |\n",
            "|[13.24,2.59,2.87,21.0,118.0,2.8,2.69,0.39,1.82,4.32,1.04,2.93,735.0] |0     |2         |\n",
            "+---------------------------------------------------------------------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Silhouette Score: 0.7274\n",
            "Cluster Centers (Centroids):\n",
            "[1.25985294e+01 2.45343137e+00 2.32186275e+00 2.06460784e+01\n",
            " 9.36960784e+01 2.05362745e+00 1.64754902e+00 3.95980392e-01\n",
            " 1.42509804e+00 4.67333332e+00 9.17843137e-01 2.39480392e+00\n",
            " 5.21558824e+02]\n",
            "[1.38507407e+01 1.77851852e+00 2.48777778e+00 1.69259259e+01\n",
            " 1.05629630e+02 2.94148148e+00 3.13666667e+00 2.98888889e-01\n",
            " 2.00703704e+00 6.27518519e+00 1.10296296e+00 3.00222222e+00\n",
            " 1.30877778e+03]\n",
            "[1.33691837e+01 2.40000000e+00 2.39265306e+00 1.85142857e+01\n",
            " 1.09081633e+02 2.44163265e+00 2.21367347e+00 3.25510204e-01\n",
            " 1.70673469e+00 5.18836735e+00 9.59714286e-01 2.84795918e+00\n",
            " 9.06346939e+02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Movie recommendation with PySpark***"
      ],
      "metadata": {
        "id": "68NmFIWG_h-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "import pandas as pd\n",
        "\n",
        "# Step 2: Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"MovieLens Recommendation Engine\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 3: Load the MovieLens 100k dataset\n",
        "# The dataset contains 100,000 ratings from 943 users on 1682 movies\n",
        "url = \"https://files.grouplens.org/datasets/movielens/ml-100k/u.data\"\n",
        "columns = ['userId', 'movieId', 'rating', 'timestamp']\n",
        "\n",
        "# Read using pandas\n",
        "df_pd = pd.read_csv(url, sep='\\t', names=columns)\n",
        "\n",
        "# Drop unnecessary columns and convert to Spark DataFrame\n",
        "df = spark.createDataFrame(df_pd.drop('timestamp', axis=1))\n",
        "\n",
        "# Display sample data\n",
        "print(\"Sample Ratings:\")\n",
        "df.show(5)\n",
        "\n",
        "# Step 4: Split data into training and testing sets (80-20 split)\n",
        "training_data, testing_data = df.randomSplit([0.8, 0.2])\n",
        "\n",
        "# Step 5: Build the ALS (Alternating Least Squares) recommendation model\n",
        "als_model = ALS(\n",
        "    userCol=\"userId\",\n",
        "    itemCol=\"movieId\",\n",
        "    ratingCol=\"rating\",\n",
        "    coldStartStrategy=\"drop\"  # Drop NaNs during prediction\n",
        ")\n",
        "\n",
        "# Train the ALS model on the training data\n",
        "model = als_model.fit(training_data)\n",
        "\n",
        "# Step 6: Predict ratings on the test data\n",
        "predictions = model.transform(testing_data)\n",
        "\n",
        "# Step 7: Evaluate the model using Root Mean Squared Error (RMSE)\n",
        "evaluator = RegressionEvaluator(\n",
        "    metricName=\"rmse\",\n",
        "    labelCol=\"rating\",\n",
        "    predictionCol=\"prediction\"\n",
        ")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root Mean Squared Error (RMSE) on test data: {rmse:.4f}\")\n",
        "\n",
        "# Step 8: Generate Top-5 movie recommendations for all users\n",
        "recommendations = model.recommendForAllUsers(5)\n",
        "\n",
        "# Display sample recommendations\n",
        "print(\"Top-5 Movie Recommendations for Users:\")\n",
        "recommendations.show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqhJr7ba2ZY5",
        "outputId": "58feb15c-e924-472d-a956-9c3e55354058"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Ratings:\n",
            "+------+-------+------+\n",
            "|userId|movieId|rating|\n",
            "+------+-------+------+\n",
            "|   196|    242|     3|\n",
            "|   186|    302|     3|\n",
            "|    22|    377|     1|\n",
            "|   244|     51|     2|\n",
            "|   166|    346|     1|\n",
            "+------+-------+------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Root Mean Squared Error (RMSE) on test data: 0.9262\n",
            "Top-5 Movie Recommendations for Users:\n",
            "+------+----------------------------------------------------------------------------------------------+\n",
            "|userId|recommendations                                                                               |\n",
            "+------+----------------------------------------------------------------------------------------------+\n",
            "|1     |[{1589, 5.3769145}, {1449, 5.1196933}, {408, 5.0904303}, {1643, 5.0285673}, {1405, 4.9508567}]|\n",
            "|2     |[{1449, 4.7590003}, {318, 4.6494007}, {963, 4.6178613}, {408, 4.6051507}, {1398, 4.5990634}]  |\n",
            "|3     |[{1268, 4.514106}, {320, 4.509019}, {838, 4.491013}, {902, 4.4837756}, {1591, 4.390137}]      |\n",
            "|4     |[{838, 5.7553835}, {1664, 5.6527557}, {1449, 5.615373}, {904, 5.603878}, {320, 5.5254235}]    |\n",
            "|5     |[{1589, 4.963531}, {1268, 4.7796016}, {1500, 4.7496305}, {114, 4.528006}, {169, 4.3986516}]   |\n",
            "+------+----------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}